{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9Q23eLqbgXM58nMJKldJk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MustafaEisaTech/Learning_TF/blob/main/Custom_Layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kiDWhsRCN4pb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDenseLayer(keras.layers.Layer):\n",
        "     def __init__(self, units=32):\n",
        "        super(CustomDenseLayer, self).__init__()\n",
        "        self.units = units\n",
        "     def build(self, input_shape):\n",
        "        self.w = self.add_weight(\n",
        "            shape = (input_shape[-1], self.units),\n",
        "            Initializer = \"random_normal\",\n",
        "            trainable = True\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            shape = (self.units, ),\n",
        "            Initializer = \"zeros\",\n",
        "            trainable = True\n",
        "        )\n",
        "\n",
        "     def call(self, inputs):\n",
        "      return tf.matmul(inputs, self.w) + self.b"
      ],
      "metadata": {
        "id": "VXA-O7akOxNS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BadDenseLayer(keras.layers.Layer):\n",
        "    def __init__(self, units = 32) -> None:\n",
        "       super(BadDenseLayer, self).__init__()\n",
        "       self.units = units\n",
        "    def build(self):\n",
        "      self.w = self.add_weight(\n",
        "          shape = (64, self.units),\n",
        "          Initializer = \"random_normal\",\n",
        "          trainable = True\n",
        "      )\n",
        "      self.b = self.add_weight(\n",
        "          shape = (self.units, ),\n",
        "          initializer = \"zeros\",\n",
        "          trainable = True\n",
        "      )\n",
        "    def call(self, inputs):\n",
        "      return tf.matmul(inputs, self.w) + self.b\n",
        ""
      ],
      "metadata": {
        "id": "bgMLcwYzUk4j"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ForgetGate(keras.layers.Layer):\n",
        "    def __init__(self, units) -> None:\n",
        "        super(ForgetGate, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_dim = input_shape[0][-1]\n",
        "        hidden_dim = input_shape[1][-1]\n",
        "        cell_dim = input_shape[2][-1]\n",
        "\n",
        "        self.w = self.add_weight(\n",
        "            shape = (input_dim + hidden_dim + cell_dim, self.units),\n",
        "            initializer = \"random_normal\",\n",
        "            trainable = True\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            shape = (self.units, ),\n",
        "            initializer = \"zeros\",\n",
        "            trainable = True,\n",
        "            name = \"Forget gate bias\"\n",
        "        )\n",
        "    def call(self, inputs):\n",
        "      x, h_prev, c_prev = inputs\n",
        "\n",
        "      concatinated_input = tf.concat([x, h_prev, c_prev], axis = -1)\n",
        "\n",
        "      forget_gate = tf.sigmoid(tf.matmul(concatinated_input, self.w) + self.b)\n",
        "\n",
        "      return forget_gate"
      ],
      "metadata": {
        "id": "YC25Hf71Y70E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LAZZAlVNaork"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}