{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP7GrIV8GVi2epEiGtM8pFC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MustafaEisaTech/Learning_TF/blob/main/CNN_with_sequential_and_functional_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kSBKDqBanMBT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "#physical_devices = tf.config.list_physical_devices('GPU')\n",
        "#tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')"
      ],
      "metadata": {
        "id": "cOA2CJIfnvjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "877063d4-0732-49f5-e4ac-1657fef19353"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sequntial API\n",
        "#We are going to use the Conv2D method and Maxpool2D from layers\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(32, 32, 3)),\n",
        "        layers.Conv2D(32, 3, padding = 'valid', activation = 'relu' ),\n",
        "        layers.MaxPool2D(),\n",
        "        layers.Conv2D(64, 3, activation = 'relu'),\n",
        "        layers.MaxPool2D(),\n",
        "        layers.Conv2D(128, 3, activation = 'relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10)\n",
        "\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 3e-4),\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "model.fit(x_train, y_train, batch_size =64, epochs = 10, verbose =2)\n",
        "model.evaluate(x_test, y_test, batch_size = 64, verbose = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgYBZweZoEfh",
        "outputId": "20b4d17a-0402-40a8-caa9-36b24e39eb94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 - 9s - 11ms/step - accuracy: 0.3084 - loss: 2.0938\n",
            "Epoch 2/10\n",
            "782/782 - 2s - 3ms/step - accuracy: 0.4693 - loss: 1.4788\n",
            "Epoch 3/10\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.5510 - loss: 1.2662\n",
            "Epoch 4/10\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.6096 - loss: 1.1116\n",
            "Epoch 5/10\n",
            "782/782 - 2s - 3ms/step - accuracy: 0.6550 - loss: 0.9923\n",
            "Epoch 6/10\n",
            "782/782 - 3s - 3ms/step - accuracy: 0.6881 - loss: 0.8989\n",
            "Epoch 7/10\n",
            "782/782 - 2s - 3ms/step - accuracy: 0.7209 - loss: 0.8098\n",
            "Epoch 8/10\n",
            "782/782 - 2s - 3ms/step - accuracy: 0.7468 - loss: 0.7293\n",
            "Epoch 9/10\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.7711 - loss: 0.6583\n",
            "Epoch 10/10\n",
            "782/782 - 2s - 3ms/step - accuracy: 0.7910 - loss: 0.6005\n",
            "157/157 - 1s - 8ms/step - accuracy: 0.6813 - loss: 0.9949\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9949035048484802, 0.6812999844551086]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Functional API\n",
        "# We are going to use Batch Normalization before we feed our convolutoin layer to the activation layer\n",
        "#Batch norm is a statistical technique\n",
        "\n",
        "def f_model():\n",
        "  inputs = keras.Input(shape =(32, 32, 3))\n",
        "  x = layers.Conv2D(\n",
        "      32, 3, padding = 'same', kernel_regularizer = regularizers.l2(0.01)\n",
        "      )(inputs)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.ReLU()(x)\n",
        "  x = layers.MaxPool2D()(x)\n",
        "  x = layers.Conv2D(\n",
        "      64, 5, padding = 'same', kernel_regularizer = regularizers.l2(0.01)\n",
        "      )(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.ReLU()(x)\n",
        "  x = layers.MaxPool2D()(x)\n",
        "  x = layers.Conv2D(\n",
        "      128, 3, padding = 'same', kernel_regularizer = regularizers.l2(0.01)\n",
        "                    )(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.ReLU()(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(64, activation = 'relu', kernel_regularizer= regularizers.l2(0.01))(x)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  outputs = layers.Dense(10)(x)\n",
        "  model = keras.Model(inputs = inputs, outputs = outputs )\n",
        "  return model\n",
        "\n",
        "model = f_model()\n",
        "\n",
        "model.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 3e-4),\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "model.fit(x_train, y_train, batch_size = 64, epochs = 150, verbose = 2)\n",
        "model.evaluate(x_test, y_test, batch_size = 64, verbose = 2)\n",
        "\n",
        "#We notice that our accuracy has improved but still has a long way to go, we can train it for longer\n",
        "#The accuracy is low because this model has only 255k parameters compared to AlexNet which had 60m\n",
        "#The reason our accuracy improved from the sequential API is because we used Batch Normalization\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        },
        "id": "kzOYZc_bpzHp",
        "outputId": "c463609a-5117-454b-ed66-a8ce2d7de913"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "782/782 - 15s - 19ms/step - accuracy: 0.3281 - loss: 3.0584\n",
            "Epoch 2/150\n",
            "782/782 - 12s - 15ms/step - accuracy: 0.4468 - loss: 1.9202\n",
            "Epoch 3/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.4925 - loss: 1.6381\n",
            "Epoch 4/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.5265 - loss: 1.5153\n",
            "Epoch 5/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.5488 - loss: 1.4457\n",
            "Epoch 6/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.5643 - loss: 1.4087\n",
            "Epoch 7/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.5765 - loss: 1.3766\n",
            "Epoch 8/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.5876 - loss: 1.3511\n",
            "Epoch 9/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.5966 - loss: 1.3250\n",
            "Epoch 10/150\n",
            "782/782 - 3s - 4ms/step - accuracy: 0.6030 - loss: 1.3162\n",
            "Epoch 11/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6149 - loss: 1.2830\n",
            "Epoch 12/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6179 - loss: 1.2802\n",
            "Epoch 13/150\n",
            "782/782 - 4s - 4ms/step - accuracy: 0.6223 - loss: 1.2678\n",
            "Epoch 14/150\n",
            "782/782 - 5s - 6ms/step - accuracy: 0.6295 - loss: 1.2558\n",
            "Epoch 15/150\n",
            "782/782 - 5s - 7ms/step - accuracy: 0.6361 - loss: 1.2421\n",
            "Epoch 16/150\n",
            "782/782 - 4s - 5ms/step - accuracy: 0.6405 - loss: 1.2312\n",
            "Epoch 17/150\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-bd182c438b02>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m )\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36mon_train_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jmEwoX3itidJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}